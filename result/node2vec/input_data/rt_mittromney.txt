An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 57 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 13.89% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 27.78% 
Learning Progress: 41.67% 
Learning Progress: 41.67% 
Learning Progress: 41.67% 
Learning Progress: 55.56% 
74,0.1635,0.384674,0.203237,0.000688161
28,0.453662,0.854775,0.761106,-0.0850941
8,0.318969,0.289189,0.0232997,-0.0945074
0,-1.04189,-1.3601,-4.8634,3.76677
4,-0.212795,-0.121421,-0.123022,0.298001
80,0.273382,0.283394,0.0730457,-0.157926
20,0.653154,0.700532,0.659293,-0.105208
1,0.419906,0.537627,0.287587,-0.236625
17,-0.0831933,-0.226801,-0.324804,0.202014
68,-0.182433,-0.109099,-0.289106,0.066919
37,-0.0289869,-0.243658,-0.0102949,0.176199
31,-0.130628,-0.099684,-0.37647,0.190504
86,0.0811146,0.0523793,0.0773651,-0.057306
58,-0.0404965,-0.0742757,-0.309832,0.272477
88,0.0203643,-0.109136,0.0103584,0.103856
32,0.00588502,-0.187054,-0.307503,0.12911
5,0.0225117,-0.0238264,-0.297507,0.144813
57,0.0725264,0.0718677,-0.0740752,0.106035
21,-0.0987668,0.0298772,-0.0769309,-0.0444914
15,-0.201808,-0.16074,-0.154606,0.21161
38,0.0303496,0.101956,-0.140854,0.00157447
6,-0.0656388,-0.0299037,-0.288915,0.165213
47,-0.0814862,-0.0223033,-0.177931,0.195992
84,-0.0918364,-0.0474091,-0.116269,-0.0253322
11,-0.200905,-0.133962,-0.0988197,0.101914
10,-0.071729,-0.0891013,0.00279545,0.191203
3,-0.0546498,-0.152039,-0.353751,0.196084
23,0.102215,-0.0435613,-0.0859358,0.0556005
56,0.109646,0.0261821,0.0243668,0.0863927
26,0.00815572,-0.0370732,-0.162779,0.207313
52,-0.0480831,0.0488937,0.0109894,0.1635
42,-0.119234,-0.140513,-0.300593,0.270357
70,-0.0156311,0.0745015,-0.0594306,-0.0576936
19,-0.0218594,-0.0276909,-0.0754298,0.137435
9,-0.0223943,-0.0855703,-0.298231,0.252552
66,-0.0236376,-0.0645143,0.0168688,0.00152308
50,-0.164198,-0.0942632,-0.354328,0.365882
35,-0.0608396,0.0926615,-0.0120158,-0.0375845
16,-0.163785,-0.187247,-0.187477,0.286003
61,0.0423815,0.233137,0.100295,-0.0491099
12,0.33593,0.187166,0.136873,-0.0340724
63,-0.0410944,-0.040792,0.0508528,-0.038372
55,-0.101872,-0.076252,-0.284444,0.323968
14,0.0363749,0.130336,0.0235615,0.130131
69,0.0858442,-0.0493422,-0.0431902,0.07943
24,-0.120914,-0.106928,-0.275482,0.205654
60,0.324786,0.17227,0.202836,-0.197216
82,0.0894193,0.159152,0.169607,-0.151201
40,-0.0548228,0.0937064,-0.295746,0.18948
53,-0.11308,-0.107117,-0.259471,0.256897
29,-0.0404768,0.084889,-0.0550142,0.0539352
7,-0.0571026,-0.113438,-0.256766,0.124577
87,0.0989253,-0.0601011,0.046789,-0.00230567
22,-0.0503537,-0.0698384,-0.323821,0.129197
79,0.0401313,0.0769972,0.0317468,-0.0101719
46,-0.0344917,-0.220056,-0.304856,0.264364
81,-0.0528104,0.0790967,-0.182675,0.0819316
65,-0.177488,0.00192546,-0.16334,0.368783
77,0.125103,0.139515,0.143121,-0.0639221
33,0.0031901,0.140276,0.16121,-0.163503
27,-0.13274,-0.207349,-0.12306,0.232526
44,-0.0232241,-0.0672732,-0.0686061,0.106783
2,-0.0840831,-0.0160457,-0.363343,0.195469
73,0.2219,0.330501,0.177774,-0.0325686
90,0.205189,0.0480138,-0.0739025,0.00523573
25,-0.00333236,-0.00353475,0.0167259,-0.0551706
45,-0.00578045,0.0556747,-0.0400307,0.0036697
36,0.0601756,0.204195,0.149419,-0.177106
43,0.169036,0.371375,0.204642,-0.150022
41,0.211339,0.239455,0.122024,-0.145804
78,0.00636016,0.0702093,-0.013431,-0.0569788
67,0.171136,0.109717,0.0423205,-0.0119668
71,-0.0856717,0.113328,0.0737718,0.12293
30,-0.121938,0.0760145,-0.306255,0.114083
13,-0.116935,-0.102532,-0.279825,0.127422
18,-0.0279364,0.044403,0.0460352,-0.00519134
48,0.172408,0.273078,0.331488,-0.0420623
39,-0.211997,-0.151755,-0.226477,0.298863
75,-0.0608947,0.0987322,0.0367574,0.133351
34,0.310858,0.177445,0.168584,-0.227155
62,0.0308465,0.0415409,0.0384173,0.145789
89,-0.0132215,0.15998,-0.164383,0.0508189
49,-0.0628618,-0.129906,-0.194661,0.178118
76,-0.0288332,-0.0326449,-0.0324882,0.0664849
72,0.168134,0.373849,0.167097,-0.0280484
64,0.110082,0.301476,0.0336358,-0.0911973
51,0.0442541,-0.013287,-0.100063,-0.0385383
83,0.00800944,-0.0743837,0.0607857,0.11246
54,0.175694,0.22977,0.151774,-0.251481
59,-0.0974697,-0.00404238,0.105448,-0.0986012
85,0.0997952,0.105557,0.0176251,0.193352
