An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 31 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 35.71% 
Learning Progress: 0.00% 
Learning Progress: 35.71% 
Learning Progress: 0.00% 
Learning Progress: 35.71% 
33,-0.095836,-0.264657,-0.160888,0.0276798
5,-0.474494,-0.829263,-0.230836,-0.37907
1,-0.181104,-0.59871,-0.0395609,-0.0676196
0,-0.0220244,1.88026,-4.82068,6.09093
22,0.0718299,0.0537034,-0.0826895,0.21502
8,-0.00920254,-0.384402,-0.033053,-0.115941
32,-0.0181821,-0.255463,0.117008,-0.184169
3,-0.0724441,-0.521486,0.17945,-0.426906
2,-0.22815,-0.29418,0.231903,-0.245744
11,-0.00433504,-0.364702,0.152034,-0.32662
21,0.0110254,-0.0967253,-0.062969,-0.100607
7,-0.132893,-0.066849,-0.0450102,0.296807
4,-0.262052,-0.579793,-0.0328618,0.0386094
34,-0.0480797,-0.25789,0.048331,-0.267546
31,-0.130899,-0.445298,-0.0127818,-0.11319
19,-0.0969737,-0.356743,0.38054,-0.280481
10,-0.140134,-0.0121761,0.0577614,-0.235837
28,0.0756487,-0.432009,0.250196,-0.108795
29,0.0848723,-0.0742535,-0.0771877,0.159726
16,-0.0224392,-0.0938076,0.108404,-0.159751
15,-0.0344135,-0.245865,0.173463,-0.132094
9,-0.179668,-0.364696,0.154298,-0.169009
13,-0.0206807,-0.207579,-0.0257158,-0.255399
20,-0.132697,-0.401998,0.0853679,-0.0671624
6,-0.144066,-0.234749,0.0680386,-0.170673
18,-0.0815044,-0.267504,0.0831558,-0.284484
26,0.0932948,-0.128386,-0.0972052,-0.271533
14,-0.116646,-0.137348,0.0922722,-0.0501155
35,-0.0697162,-0.181229,0.0309197,-0.0197921
27,-0.193188,-0.31771,-0.000851338,-0.346347
24,0.0547046,-0.156234,0.0253188,-0.0539751
17,-0.105749,-0.275479,0.0943594,-0.144473
12,-0.0147272,-0.184574,-0.172063,-0.04591
23,0.0711228,-0.280012,0.0670221,-0.0856563
30,0.072675,-0.322158,-0.00623196,-0.194092
25,-0.0605713,-0.250792,-0.00350576,-0.127348
