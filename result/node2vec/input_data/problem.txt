An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 86 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 27.17% 
Learning Progress: 54.35% 
23,0.0447866,-0.0634532,0.266891,-0.106107
0,0.570506,-0.555518,4.67446,-3.16613
45,0.0797896,-0.260913,0.231662,-0.277698
9,-0.0819481,0.0561812,-0.16966,0.135278
31,0.10909,-0.0326758,-0.00305627,0.0130183
46,0.0544092,-0.187454,0.398609,-0.18311
27,-0.107528,0.0486974,0.147788,-0.0591772
24,0.21638,-0.203543,0.291346,-0.194327
17,0.0532317,-0.0572476,0.357027,-0.122283
16,0.0282636,0.161914,0.167251,-0.205446
6,-0.288215,0.106547,-0.509875,0.321722
12,0.0368152,0.0372287,-0.0228258,0.0808161
44,0.0771753,-0.094311,0.334837,-0.327438
22,-0.23149,0.0347576,0.120804,-0.0937635
14,0.086392,-0.100642,0.0711193,-0.128706
3,-0.398835,0.209524,-0.790216,0.53159
7,-0.103442,0.328574,-0.129324,0.0357892
29,0.239675,-0.184964,0.246056,-0.310873
34,0.237132,-0.0824615,0.291368,-0.308392
25,0.134311,-0.198718,0.302271,-0.11319
15,0.0689238,0.0543219,0.153002,-0.309601
4,-0.165676,0.164466,-0.175195,0.261576
5,-0.430535,0.353846,-0.449429,0.123375
11,0.0480053,-0.146261,-0.0806411,-0.0151157
39,0.21028,-0.13758,0.44371,-0.327109
42,0.0769642,-0.282739,0.315547,-0.232036
26,0.18641,-0.228241,0.304166,-0.260074
10,-0.184721,0.145437,-0.359082,0.12639
37,0.286642,-0.111479,0.270141,-0.286304
18,0.105928,-0.14427,0.169555,-0.178889
2,-0.506816,0.249991,-1.08697,0.703724
21,0.247014,-0.212579,0.111974,-0.162424
20,0.010888,-0.215033,0.290739,-0.102917
30,0.0649332,-0.0863901,0.109835,-0.0922947
33,0.00679987,0.0881533,0.184658,-0.0857049
19,0.00185479,-0.119609,0.36172,-0.0983964
28,0.197457,-0.265107,0.354367,-0.098902
35,0.239223,-0.132862,0.338983,-0.239297
8,-0.146631,0.254284,-0.212226,0.259777
13,0.252149,-0.191712,0.116738,-0.263954
40,0.163397,-0.233413,0.356292,-0.223826
41,0.104774,-0.21799,0.265009,-0.176285
32,0.15211,-0.0891198,0.299309,-0.135175
36,0.132843,-0.104717,0.35216,-0.0887297
1,-0.620626,0.603331,-1.49004,1.21386
38,0.23308,-0.149603,0.403032,-0.173934
43,0.216349,-0.127984,0.398765,-0.139693
