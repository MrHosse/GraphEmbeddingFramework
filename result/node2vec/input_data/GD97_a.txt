An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 166 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 14.88% 
Learning Progress: 14.88% 
Learning Progress: 0.00% 
Learning Progress: 29.76% 
Learning Progress: 44.64% 
Learning Progress: 59.52% 
56,-0.0996009,-0.0651966,-0.0733903,-0.116776
45,-0.0582523,0.244477,0.0781132,0.00577753
0,1.33367,5.2336,2.53577,3.58324
61,-0.0718861,-0.409656,-0.302033,-0.212343
34,-0.249101,-0.605903,-0.187823,-0.317531
8,-0.0330622,-0.492581,-0.247531,-0.178186
7,0.0190968,-0.3298,-0.137436,-0.350275
31,-0.00768217,-0.0882488,0.0459204,0.0506283
15,-0.0178158,-0.274391,-0.171422,-0.0484525
48,-0.175429,-0.312163,-0.118252,-0.170859
63,0.0985661,-0.00747459,0.126226,0.0923839
5,0.00682016,0.271179,0.0413454,0.193157
77,-0.0227974,-0.319278,0.0372726,-0.212709
26,0.135787,0.380808,0.0534272,0.330696
4,0.0835479,0.122955,0.146223,0.0874684
36,0.169503,0.2268,0.0163183,0.129673
76,-0.0151665,-0.435586,-0.241783,-0.171644
17,-0.074595,-0.471908,-0.179047,-0.0984144
68,-0.197007,-0.456684,-0.177792,-0.300195
32,-0.0170814,0.258253,0.110258,0.0189825
38,-0.0205405,-0.073619,-0.092333,-0.0160736
1,-0.0314456,-0.0183517,0.0189484,0.0396434
59,-0.103087,-0.375962,-0.145275,-0.197218
40,-0.243868,-0.643644,-0.185717,-0.252766
12,-0.118998,-0.11932,-0.0271397,-0.147568
74,-0.0516933,0.0461868,0.0626635,0.0770444
16,-0.16388,-1.02838,-0.454838,-0.555574
44,0.0132725,-0.33797,-0.184554,-0.188163
28,0.00909058,-0.424535,-0.194423,-0.156004
18,0.066326,-0.0590798,-0.0119927,-0.0297279
11,-0.199846,-0.497789,-0.160565,-0.18816
27,-0.163049,-0.512495,-0.229768,-0.110935
6,-0.00512926,0.131264,0.124489,0.0664043
71,-0.0528726,-0.381239,0.0208605,-0.145063
22,-0.0681572,-0.353948,-0.0476995,-0.0714205
82,-0.0835677,-0.330678,0.0542607,-0.173398
30,-0.368771,-1.13796,-0.603252,-0.657854
60,-0.214372,-0.511747,-0.19879,-0.212072
23,0.00839559,0.355981,0.0936883,0.194009
20,-0.227914,-0.466586,-0.142841,-0.0877482
83,-0.00692272,-0.490092,-0.0902391,-0.0238485
37,-0.137971,-0.388132,0.00390585,-0.283751
64,-0.0330783,-0.0156793,-0.0406841,-0.0911551
10,-0.0519317,-0.197897,0.041669,-0.00704986
9,0.0921731,0.0264609,-0.0249331,0.126166
13,-0.0797931,-0.210942,-0.151803,-0.0106318
2,0.0801324,-0.290056,-0.155434,-0.0392705
67,-0.178713,-0.593134,-0.200067,-0.429216
75,-0.0719508,-0.0465503,-0.0645763,-0.203272
62,-0.114616,-0.432421,-0.178628,-0.161419
43,-0.104472,-0.138669,-0.154985,-0.00255361
33,-0.0756616,-0.312786,-0.0917922,-0.132818
35,0.168585,0.341715,0.131983,0.133529
52,-0.0393755,-0.344008,-0.290642,-0.405571
49,-0.214655,-0.97222,-0.350871,-0.678927
14,-0.0724321,-0.609793,-0.379965,-0.288361
65,-0.198317,-0.376178,-0.286963,-0.290549
3,-0.103487,0.0784912,-0.0432148,-0.129242
24,-0.0618123,-0.181076,0.0334426,-0.0300085
41,-0.288756,-0.708161,-0.144983,-0.421813
81,0.0146124,-0.130811,0.0163854,-0.0533934
79,-0.0736724,-0.210587,-0.277244,-0.270671
50,-0.112046,-0.326458,-0.105675,-0.130504
21,0.00763265,0.266452,0.157379,0.168284
19,0.154614,0.234995,-0.00881759,0.171618
69,-0.113666,-0.425674,0.0206041,-0.0825859
80,-0.092192,-0.226255,0.0168018,-0.114517
29,-0.131208,-0.311808,-0.0557306,-0.0836597
58,-0.239691,-0.626425,0.0407059,-0.209156
55,-0.0824585,-0.644534,-0.175946,-0.126244
57,-0.079239,-0.3283,-0.0888086,-0.0582635
84,0.0186944,-0.0984485,-0.0896211,-0.0653097
51,-0.21859,-0.415559,-0.0118562,-0.0320705
42,-0.188836,-0.28883,-0.0628529,-0.0636975
70,-0.173237,-0.464563,-0.150905,-0.229843
73,-0.0510831,-0.0561735,0.0485585,-0.0138034
39,-0.00549092,-0.00934461,0.0622372,0.0188008
53,-0.246167,-0.526085,-0.095161,-0.16513
54,-0.136097,-0.20704,-0.00777718,-0.151308
47,0.0229746,-0.44133,-0.243174,-0.28145
25,-0.11296,-0.706962,-0.144821,-0.322454
78,-0.117167,-0.154423,-0.124147,-0.0189327
72,-0.0714,-0.461937,-0.0690906,-0.119752
46,-0.0540319,-0.0446385,0.0306507,-0.0639539
66,-0.154212,-0.271247,0.0397532,-0.0135662
