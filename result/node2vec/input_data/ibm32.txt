An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 126 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 39.06% 
Learning Progress: 78.12% 
8,0.00879488,0.909623,5.3943,3.69612
20,0.165996,0.678232,5.35872,3.74888
15,-0.192231,0.147183,5.03849,3.57954
11,-0.060326,0.0934984,5.51383,3.50405
13,0.18283,0.113462,5.09182,3.11367
9,-0.12333,0.243823,5.26121,3.31505
2,-0.13971,0.274196,5.16196,3.24758
3,-0.123468,0.359518,5.29082,3.47143
5,-0.0797177,0.455982,5.17877,3.45882
27,0.173262,0.302324,4.986,3.36724
29,0.063642,0.348489,5.44342,3.26668
1,-0.0980388,0.448063,5.17066,3.47517
18,0.00614332,0.454045,5.549,3.82868
10,-0.0394581,0.262499,5.26861,3.60513
25,-0.100895,0.575842,5.76124,4.18445
22,0.311373,0.30279,5.52012,3.32904
26,0.174948,0.30646,5.62657,3.53512
19,-0.00225058,-0.0117207,5.5485,3.34908
23,-0.327234,0.0989382,5.10031,3.48143
30,0.0210273,0.359461,5.59566,4.05975
31,-0.196418,0.453504,5.26832,3.56177
7,-0.281405,0.599864,5.4051,3.57982
28,-0.175187,0.0267845,5.39067,3.31573
32,-0.135377,0.174694,5.45882,3.35758
21,-0.2261,0.27396,4.9956,3.24838
4,-0.140277,0.598233,5.48895,3.69983
16,0.00409245,0.552113,5.36978,3.60206
6,-0.0997992,0.665239,4.77902,3.34953
17,-0.0501998,0.653861,5.22834,3.48668
12,0.0949182,0.421882,4.79473,3.34616
14,-0.437378,0.527522,4.88277,3.31574
24,0.351386,0.437883,5.11139,3.5529
