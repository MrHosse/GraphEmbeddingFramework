An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 149 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 23.58% 
Learning Progress: 0.00% 
Learning Progress: 70.75% 
14,0.150723,-0.3039,-5.43566,3.39068
21,-0.191246,-0.214035,-5.35193,3.12708
18,-0.240355,-0.31102,-5.32615,3.51576
29,-0.0633423,-0.306582,-5.43733,3.79069
31,-0.18134,-0.134151,-6.01279,3.78015
35,-0.218109,-0.0656431,-5.59847,3.37832
17,0.0142512,-0.00578864,-6.10716,3.7188
25,0.0759129,-0.122335,-5.66844,3.6932
33,0.234147,0.0580643,-5.88058,3.43611
36,0.0147878,-0.0619468,-5.6766,3.64747
39,0.387158,-0.0233128,-5.47449,3.55336
44,-0.222704,-0.340422,-5.74652,3.59325
48,-0.0185425,-0.269465,-5.99211,3.79613
3,0.162693,-0.514972,-5.62764,3.40249
9,-0.0413002,-0.693767,-5.80076,3.69955
6,-0.236643,-0.505177,-5.81106,3.62165
15,-0.0613089,-0.528698,-5.77365,3.68116
22,-0.102191,-0.241654,-5.14253,3.78932
37,-0.18277,-0.272197,-5.87671,3.79109
43,-0.323328,-0.345358,-5.65643,3.81653
7,0.133665,-0.591505,-5.93354,3.68053
20,-0.262059,-0.513014,-5.15098,3.84838
32,0.011366,-0.222652,-5.57539,3.71815
26,0.0237585,-0.0484338,-5.91979,3.45039
38,0.0439743,-0.263907,-5.36574,3.80297
50,0.015171,-0.427969,-5.8844,3.75573
47,0.0279034,-0.25406,-5.70803,3.98534
52,-0.0440185,-0.241457,-6.08507,4.23741
13,0.256436,-0.174345,-5.09368,3.36957
42,0.162739,-0.21454,-5.39536,3.78636
49,-0.00458773,-0.273653,-5.61227,4.0741
12,0.163701,-0.536708,-5.79223,3.59593
5,0.15532,-0.427457,-5.63681,3.86889
11,0.313708,-0.514292,-6.0046,3.83084
4,0.0850855,-0.382845,-5.54776,3.67662
1,0.308754,-0.621229,-6.07809,3.97048
27,0.327884,-0.550153,-5.81137,3.76777
34,0.191029,-0.431636,-5.67896,3.98508
41,0.219617,-0.296807,-5.55027,3.53477
8,-0.0632872,-0.525413,-5.50162,3.33333
23,-0.0449452,-0.490418,-5.77599,3.53778
10,-0.0440861,-0.634228,-5.70051,3.74056
16,0.259978,-0.671176,-5.83412,3.85045
19,0.0402332,-0.496652,-5.15034,3.52142
24,-0.21001,-0.393367,-5.1838,3.42118
40,-0.200321,-0.321715,-5.6883,3.78598
45,0.0259639,-0.357528,-5.47503,4.04922
28,-0.0560567,-0.456478,-5.44212,3.33663
46,0.135602,-0.179045,-5.39453,3.96605
51,0.0961856,-0.171599,-5.6636,3.81293
2,0.343643,-0.664402,-5.94061,3.74846
30,0.294194,-0.275041,-5.575,3.57201
53,0.0163427,-0.264013,-5.92511,3.88679
