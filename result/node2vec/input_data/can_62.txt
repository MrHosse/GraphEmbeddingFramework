An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 140 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 20.16% 
Learning Progress: 40.32% 
Learning Progress: 40.32% 
Learning Progress: 60.48% 
Learning Progress: 60.48% 
46,-0.471834,-0.141018,-1.5737,0.417034
45,-0.686676,-0.431397,-2.39626,0.579291
44,-2.78095,-2.1316,-9.65508,2.11845
12,-2.08667,-0.797754,-3.41167,0.601468
11,-2.07239,-0.904637,-3.4295,0.557393
10,-2.08519,-1.0368,-3.52871,0.599267
5,-2.4093,-1.25587,-4.10327,0.620438
2,-3.79177,-2.87136,-7.74863,1.85911
13,-0.625881,-0.0352836,-0.886087,0.256268
47,-0.656167,-0.0043782,-1.24967,0.329113
16,-1.94461,-0.546966,-3.69853,0.338803
14,-1.85322,-0.727968,-3.6489,0.530004
4,-2.75701,-1.47931,-4.36557,0.726426
3,-2.85754,-1.56695,-4.50089,0.716022
1,-5.39913,-3.49498,-8.79483,-0.428559
20,-1.49846,-0.40542,-1.78192,-0.00936987
7,-1.8428,-0.725862,-2.43813,0.0616297
6,-2.11929,-1.114,-3.43859,0.622373
48,-1.69859,-0.85156,-3.33282,0.220376
29,-2.61234,-1.27647,-4.76789,0.334102
27,-2.65409,-1.17756,-4.80619,0.310128
26,-2.51796,-1.11692,-4.61566,0.266749
25,-2.28317,-0.93842,-4.36154,0.236809
24,-2.155,-0.650626,-4.1835,0.13574
23,-1.95296,-0.647627,-3.9962,0.179666
17,-1.89357,-0.375441,-4.07903,0.0671736
56,-0.929418,-0.237847,-1.99188,-0.223202
52,-0.863914,-0.371011,-2.13686,-0.201034
15,-0.672241,0.373842,-0.898294,-0.0506975
58,-1.04901,-0.0244381,-1.60001,0.0742744
19,-1.1577,-0.187001,-1.75122,0.0977342
9,-1.21421,-0.5993,-2.29894,0.234182
35,-2.00898,-0.905519,-3.84912,0.261105
57,-0.776949,-0.698836,-1.87781,0.145459
37,-1.72351,-0.299462,-2.69405,0.138365
34,-1.68747,-0.487385,-3.10312,0.147
33,-1.69452,-0.735748,-3.25332,0.220781
32,-1.51634,-0.577527,-2.85728,0.174613
31,-1.45184,-0.0902529,-2.04999,0.16069
8,-1.28374,-0.606215,-2.22002,0.385635
18,-1.51772,-0.383022,-2.97295,0.100105
43,-0.579531,-0.0859924,-1.37863,0.0232459
36,-1.75894,-0.552074,-2.75324,0.191618
60,-0.694831,0.0176106,-1.11599,0.0962574
59,-1.05963,-0.356526,-1.54876,0.321267
21,-1.29134,-0.418353,-2.59606,0.123466
22,-1.00124,-0.308648,-2.12258,0.0841896
38,-4.21529,-4.30126,-9.81375,0.655552
61,-0.70895,-0.0330796,-1.43051,0.102759
55,-1.07253,-0.0856592,-1.51179,0.119374
54,-1.7142,-1.17585,-3.05265,0.29164
41,-1.71351,-1.36386,-3.25124,0.254557
40,-1.86919,-1.54807,-3.56495,0.32791
39,-2.06794,-1.75399,-3.92633,0.398769
30,-1.82129,-0.343075,-2.21334,0.207511
42,-1.43071,-0.132739,-1.94591,0.171876
49,-0.654848,0.0191603,-1.31528,0.044972
62,-1.55413,0.00358827,-1.62905,0.122868
28,-3.36823,-2.26894,-8.39007,-0.59788
50,-1.36064,-0.334441,-2.15229,0.164186
51,-0.940763,-0.217371,-1.74227,0.115904
53,-0.570617,0.394122,-0.93874,0.165663
