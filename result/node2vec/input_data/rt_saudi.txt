An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 33 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 50.00% 
Learning Progress: 0.00% 
22,-0.0831926,0.100149,-0.103001,-0.0161588
14,0.118292,-0.212528,0.122495,0.142967
0,1.57683,-1.87344,4.1605,2.72744
15,-0.0307905,0.253627,-0.0672091,-0.0135413
12,-0.20184,0.264339,-0.119429,0.00719273
3,-0.0681271,0.00537094,0.178364,0.139939
6,-0.133861,-0.068367,0.0637066,-0.0874235
2,0.118214,-0.135101,0.274361,0.166413
10,0.092823,-0.299,0.323463,0.167152
23,-0.268962,0.38404,-0.138404,0.00830807
18,0.0244487,-0.124845,0.373694,0.175022
16,-0.0190121,0.0485339,-0.0383611,-0.0184207
7,0.0646799,-0.172143,0.142631,0.180382
20,-0.017793,-0.0285915,0.0551959,0.0506936
1,-0.168598,0.0308274,0.154832,0.0187282
24,-0.107241,0.34571,-0.0690803,-0.188297
19,-0.178977,0.365798,-0.140213,-0.172323
25,-0.097624,0.201971,-0.175185,-0.177278
11,0.0118325,0.224261,0.164476,0.0900479
8,0.11739,-0.225014,0.183669,0.255546
13,0.159692,-0.0638356,0.104773,0.192545
17,-0.0758601,0.230841,-0.0519362,-0.0235261
9,-0.121054,0.0974611,-0.110376,-0.0695768
5,-0.0704607,0.264255,-0.0315133,-0.0833893
4,0.000323161,0.169255,0.0111135,0.120215
21,0.021903,0.0325889,-0.00559529,0.0581428
