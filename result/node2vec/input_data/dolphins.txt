An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 159 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 20.16% 
Learning Progress: 20.16% 
Learning Progress: 40.32% 
Learning Progress: 40.32% 
48,-0.134996,0.058556,-0.111156,-0.014301
1,-1.34335,0.484601,0.605075,-0.179203
0,7.56009,-5.12541,-5.30348,0.455659
45,-0.285625,0.189003,-0.313539,-0.0511804
39,-0.48396,0.314214,0.411898,-0.0274059
21,-0.589311,0.440128,0.569571,0.000817549
9,-0.195891,-0.0053809,0.116591,0.0512237
4,-0.34243,0.157581,0.111114,-0.00117932
28,0.0440042,0.045993,0.159672,0.00607673
26,-0.50003,0.105698,0.0794549,0.0932553
18,-0.617925,0.139343,0.232301,-0.0435086
10,-0.621044,0.181431,0.268276,0.00189371
7,-0.433359,0.119429,0.04239,0.0116039
17,-0.636136,0.511529,0.660327,-0.139808
15,-0.58255,0.382749,0.458631,-0.21571
58,-0.200504,0.124968,-0.255768,-0.0287883
49,-0.0182283,0.0997063,-0.0223242,-0.0644682
33,-0.261803,0.0966257,0.357459,-0.0145384
14,-0.412905,-0.0443715,-0.109637,0.0496722
6,0.134533,-0.223826,-0.0822456,-0.0628333
54,-0.318606,-0.0706816,0.27519,-0.104364
44,-1.22605,0.838542,0.75345,-0.15709
56,-0.324918,0.143733,0.205001,0.0354072
52,-0.342974,0.198583,0.265551,-0.00308506
5,-0.213044,0.164535,0.0148687,-0.0707351
61,-0.216795,0.144608,0.214979,-0.046012
51,0.107725,-0.00977655,0.163742,-0.104668
34,-0.727737,0.304086,0.55983,-0.138749
22,-1.11658,0.613151,0.818773,-0.145122
19,-1.3392,0.525291,0.856392,-0.287852
16,-1.25499,0.55023,0.838101,-0.15451
2,-0.00977247,-0.259571,-0.139091,-0.126522
50,-0.319507,0.252289,0.211472,-0.0932524
35,-0.0507142,0.181589,0.245795,-0.118496
8,0.244048,-0.00988229,0.0257041,0.103489
20,-0.160326,0.0927523,-0.119001,0.0498826
36,-0.0534705,-0.17697,0.296533,-0.0967855
30,-0.286721,-0.105003,0.426976,-0.0620377
27,-0.260718,0.127663,-0.211261,-0.131496
12,0.157876,-0.0400288,0.000437543,-0.0508032
11,-0.076306,0.0968148,-0.115144,-0.0700356
3,0.137713,-0.143767,-0.1918,0.0588469
53,-0.355337,0.26437,-0.0509827,0.0667574
55,-0.143563,-0.0209036,-0.13294,0.04942
57,0.0247852,-0.0553276,-0.0477227,0.00354746
13,-0.162551,0.0256731,-0.10574,0.112931
32,-0.0255847,0.110507,0.277684,0.0534622
60,-0.0896347,0.227328,-0.0321478,0.0237368
43,0.023655,-0.00150679,0.0380596,0.0542373
47,-0.758154,0.559096,0.496125,-0.0746762
46,-0.41213,0.176197,0.169396,0.0546238
31,-0.098954,0.0662225,0.013975,0.0355651
29,0.138636,-0.0982375,0.21416,0.0762277
37,-0.456732,0.24349,-0.124789,0.0932627
42,-0.0429499,0.0587262,0.00307579,-0.092214
24,-0.0183541,-0.103365,-0.126191,0.0413683
23,-0.0804697,-0.00133996,-0.0195941,-0.043008
62,0.150774,-0.259867,0.203224,-0.0653801
38,-0.734025,0.621852,-0.0345495,-0.0655505
59,-0.490039,0.330367,-0.03816,-0.033445
40,-0.401933,0.0869449,-0.00568609,-0.047432
25,-0.43027,0.350478,0.519683,-0.123428
41,0.0962939,-0.00734003,-0.32674,-0.0740228
