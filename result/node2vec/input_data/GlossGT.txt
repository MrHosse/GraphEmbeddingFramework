An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 122 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 18.66% 
Learning Progress: 37.31% 
Learning Progress: 55.97% 
Learning Progress: 74.63% 
Learning Progress: 74.63% 
Learning Progress: 74.63% 
28,0.77736,0.932381,0.120458,-0.481528
6,0.926537,1.21639,0.183331,-0.203941
30,1.15606,0.864378,1.05348,-0.521913
0,-0.597477,-0.519577,1.70558,-1.70648
48,0.46906,0.466508,0.631517,-0.560996
58,1.08378,0.909832,0.41205,-1.15354
69,0.979706,0.772857,0.498768,-1.16767
39,0.798634,0.588423,0.0831073,-0.812488
22,0.797576,0.629132,0.0547991,-0.909441
71,0.969,-0.15514,-0.194068,-1.60283
63,0.422308,0.367057,0.313804,-0.587412
62,0.403062,0.417891,0.503925,-0.481513
26,0.742068,0.680232,0.105832,-0.599117
45,1.07593,0.0446216,-0.22561,-1.60011
61,0.491408,0.643471,0.166604,-0.48595
36,0.278476,0.380771,0.449766,-0.373734
38,0.501282,0.632947,0.148741,-0.582871
12,0.21991,0.125645,1.1417,-0.356229
67,0.622834,0.510803,0.160501,-0.403372
4,0.823832,0.850232,0.0980709,-0.539462
50,0.198205,0.276774,1.25852,-0.422703
40,0.806377,0.877675,0.219846,-0.930469
32,0.789912,0.819667,0.281922,-0.872739
54,0.208874,0.403329,0.828122,-0.387197
43,0.1535,0.385152,1.33705,-0.633531
17,0.711798,0.918304,0.838462,-1.12551
65,0.529173,0.59567,1.1773,-0.870926
60,0.1991,0.411716,0.808759,-0.426085
56,0.269101,0.350113,0.437235,-0.324961
57,0.3553,0.528476,0.1294,-0.583663
2,0.537266,0.460394,0.210224,-0.319468
19,0.742054,0.954656,1.03174,-1.20313
72,0.816817,0.823311,1.20365,-1.15069
21,0.651839,0.529197,0.179544,-0.447321
11,0.533114,0.505385,0.507394,-0.624355
64,0.388851,0.440983,0.465902,-0.571441
7,0.384504,0.453546,0.215637,-0.555554
47,0.681644,0.428785,0.155248,-0.523194
51,1.14401,1.0081,0.644576,-1.13539
68,0.918477,0.927922,0.845917,-1.11737
35,0.715823,0.673601,-0.0561829,-0.543689
52,0.789097,0.694475,0.00997348,-0.84875
13,0.36588,0.37039,0.346887,-0.417533
15,0.557041,0.527574,0.112659,-0.49696
31,0.450172,0.54563,0.733463,-0.632442
59,0.333189,0.358236,0.717423,-0.603085
25,0.462799,0.334751,0.46677,-0.628933
27,0.228925,0.401468,0.9804,-0.55175
20,1.03102,1.12736,0.507054,-1.05649
18,0.507516,0.454827,0.319692,-0.514064
37,0.624428,0.487156,0.190189,-0.652791
29,0.382137,0.624196,0.560905,-0.561347
10,0.599656,0.736707,0.0837337,-0.747723
46,1.02853,0.970658,0.0969032,-0.806073
42,0.929296,0.89333,0.0808355,-0.891871
8,0.536614,0.587159,0.267157,-0.471418
49,0.679048,0.587559,0.0804225,-0.636954
16,0.665985,0.788755,0.0537589,-0.558681
53,0.303937,0.362374,0.725975,-0.425308
9,0.295418,0.247366,1.17385,-0.534927
41,0.465444,0.483244,0.255878,-0.443939
14,0.452867,0.460994,0.327524,-0.596395
33,0.262245,0.42409,0.522105,-0.474875
55,0.583408,0.710256,0.112357,-0.42552
3,0.492063,0.603518,0.292865,-0.475998
1,0.355502,0.285128,0.607085,-0.387333
66,0.55276,0.576624,0.107234,-0.539126
44,0.757241,0.614398,0.0645772,-0.543816
