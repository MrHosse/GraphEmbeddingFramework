An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 124 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 14.53% 
Learning Progress: 14.53% 
Learning Progress: 29.07% 
Learning Progress: 43.60% 
28,0.0197441,0.0393172,0.057081,-0.0016367
0,-4.51184,-0.297057,-2.51461,11.3654
40,0.158386,-0.101691,0.132759,-0.772315
15,-0.14494,0.0901572,0.0973438,-0.186721
6,-0.23006,-0.0110222,0.168198,-0.129969
19,-0.0370162,0.0020894,-0.0368869,0.299356
12,-0.252929,-0.0132781,0.132447,-0.103075
11,0.0799232,-0.0494343,-0.146947,-0.0395498
48,0.0246803,0.123533,0.0180594,-0.0974024
27,-0.0274543,0.0978377,0.00946345,-0.25327
30,0.110001,-0.125572,0.178696,-0.808367
16,-0.154517,-0.0873498,0.00774541,-0.242494
3,0.0271837,0.0478549,-0.227063,-0.359698
82,-0.0543799,-0.107775,0.155775,-0.376576
76,0.197193,-0.0512842,-0.0478646,-0.17011
32,-0.110974,-0.0974967,-0.045279,-0.0810259
2,0.138219,0.065405,-0.0645859,-0.437008
26,0.388244,-0.0549703,-0.0456941,-0.472466
51,0.0781215,0.111047,-0.172901,0.0471644
14,0.0643603,-0.0219107,-0.242742,0.300623
47,-0.192061,0.0126725,-0.0487232,-0.0832116
36,0.50257,-0.148097,0.166653,-0.802145
54,-0.199276,-0.0979755,-0.0224288,-0.312995
56,-0.0305329,-0.0918566,0.050257,-0.269403
20,0.075703,0.0860797,0.0343948,-0.443412
8,0.0195435,-0.137258,0.0751627,-0.265828
33,0.278562,-0.0388345,0.0256774,-0.641331
7,0.326927,-0.106955,0.10925,-0.439985
42,0.163697,0.0752676,0.0492015,-0.51217
35,0.371009,-0.0696709,-0.0371186,-0.551738
1,0.294511,-0.161953,-0.0508387,-0.213858
62,0.187084,0.109556,-0.180522,-0.186353
60,-0.0610111,-0.0882573,0.149572,-0.0662201
49,-0.0179729,-0.0163993,0.0816263,-0.111402
5,-0.121718,0.10828,-0.113718,0.180187
22,-0.0546048,-0.0843924,0.199407,-0.410577
65,0.00116239,0.0348911,0.0636354,0.0871182
77,0.232919,0.0770088,-0.104216,-0.0492032
45,0.139224,0.0104581,0.501207,-0.684734
85,0.18871,-0.0335366,-0.0512355,-0.320765
63,-0.0494068,-0.0536295,-0.0858699,0.167227
39,0.0651156,-0.0316511,-0.103304,-0.0277914
38,0.0424623,0.0521168,-0.195465,0.246269
66,-0.0207198,0.0245819,0.0195575,0.0921706
24,-0.35327,0.0767734,-0.0737811,0.0993783
55,-0.0718412,0.020645,0.301311,-0.334343
4,-0.164741,0.0133807,-0.0299269,0.126926
81,-0.0758286,0.0409381,0.123486,-0.203384
52,0.000326939,-0.0560605,-0.196889,-0.0716006
25,-0.030827,-0.0360442,-0.0177757,-0.0975693
17,0.0255141,-0.0532776,-0.186094,0.120347
61,0.218817,0.0455767,0.139045,-0.27303
37,-0.0166217,-0.0958358,-0.0566692,-0.023914
18,-0.0223846,-0.0921593,-0.150346,-0.0984788
80,0.0186396,-0.0292497,-0.0887534,-0.071952
44,0.289104,0.0845095,0.0334081,-0.340974
70,0.0713769,0.0210128,-0.0129045,0.0483397
46,0.0700968,-0.110131,-0.157176,-0.306683
72,0.00692551,0.10645,0.227759,-0.467884
43,0.136904,-0.0120298,0.178716,-0.669952
23,-0.00591943,0.0075222,-0.00175757,-0.376457
9,-0.0319258,-0.0118375,-0.146992,-0.0673085
71,0.257148,0.0265747,-0.0956209,-0.235989
83,0.146184,0.115067,-0.00090612,-0.108235
86,0.0896794,0.031638,0.1787,-0.185573
69,-0.180329,0.0462147,0.0211281,-0.205168
68,0.107377,-0.0572346,0.0510917,-0.181408
75,-0.0252515,-0.116217,-0.0325569,-0.0411736
74,0.105261,-0.0528629,-0.0034642,-0.0667744
57,0.0895799,-0.0513733,-0.0960091,-0.0954528
21,0.0171679,0.0886769,-0.0915148,0.28131
29,-0.170677,0.0171088,-0.171507,0.294418
10,-0.0167481,-0.00609457,-0.109038,0.0164687
53,0.0434079,-0.0477355,0.107636,-0.531732
58,0.500842,-0.0824935,0.217234,-0.287119
34,-0.14833,-0.087852,-0.00420425,-0.30538
79,-0.159792,0.00106452,-0.0410637,-0.393768
31,0.0801309,-0.0955413,-0.145577,-0.0196315
41,-0.0285117,0.0422839,0.0600657,-0.329197
13,-0.177924,0.0875612,-0.199059,0.223634
73,-0.120637,0.0374973,0.0185968,-0.498042
64,0.0719705,0.0991888,0.226637,-0.285993
84,0.0279249,0.0393337,-0.0385988,-0.147065
67,0.0268542,-0.048371,0.0986606,-0.128045
59,-0.0696605,0.021888,0.302596,-0.460133
78,0.257414,0.0758821,0.272319,-0.280421
50,0.0344107,-0.0219097,-0.16586,0.0907987
