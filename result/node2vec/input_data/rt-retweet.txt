An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 117 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 13.02% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 26.04% 
Learning Progress: 26.04% 
Learning Progress: 39.06% 
Learning Progress: 52.08% 
54,-0.00795813,0.0248037,0.649002,0.448559
8,-0.186559,0.148683,0.967939,0.604105
6,-0.208437,-0.00983259,0.721502,0.526849
1,-0.0527819,0.162223,0.425286,0.244509
0,5.71814,-0.0495392,-6.6107,-4.94664
15,-0.0848417,0.0537038,0.111803,0.145795
12,-0.0727034,-0.116258,-0.119298,-0.0340137
28,-0.197377,0.0412592,0.544638,0.4513
25,-0.208432,0.112033,-0.148786,-0.14376
3,-0.148518,-0.0713499,-0.20713,0.0101555
62,-0.15942,-0.101857,-0.0370824,-0.0661643
69,-0.111874,-0.0608913,-0.415988,-0.18955
95,0.000584283,-0.0403622,0.1706,0.133336
63,0.0143393,0.0741139,-0.335121,-0.194952
51,-0.0822663,-0.0215148,0.381735,0.295731
23,0.0722128,0.0610859,0.187989,0.0670773
22,0.0675491,-0.0281794,0.110775,0.0421968
48,0.0453598,-0.0222723,-0.165322,-0.137283
14,0.0915525,-0.130125,0.129066,0.079241
73,-0.017193,-0.0359338,0.00904445,-0.0830901
11,-0.0721446,-0.00934564,-0.250848,-0.127843
53,-0.113114,0.0458961,0.392758,0.229455
34,-0.0659537,-0.0488418,-0.160135,-0.115892
88,0.00356342,0.0464431,0.151809,0.153968
41,0.0398877,-0.1195,0.422778,0.0865897
50,0.395729,0.0312386,0.359255,0.14303
4,0.0535795,0.0756736,-0.0986899,-0.189283
17,-0.0164424,0.0410012,0.0254868,-0.0242451
5,0.0504073,0.114052,-0.0851057,-0.09903
40,0.0240341,-0.0997394,0.174172,0.0713935
9,-0.103979,0.0651036,-0.238446,-0.143187
70,0.0358607,-0.0803814,0.240891,0.0919924
49,0.0658395,0.0780523,-0.079362,-0.225554
10,0.0110825,0.0668149,-0.180279,-0.22671
13,-0.107436,0.0784014,-0.216566,-0.0982732
56,0.0918077,-0.034805,0.469019,0.422401
2,-0.117098,-0.0721722,-0.0668573,-0.197133
85,0.0856294,-0.0554853,0.0782729,-0.00678399
37,-0.138457,-0.00917106,-0.0977226,-0.228609
21,-0.0307326,0.0542207,0.250421,0.103466
7,0.0919891,0.0803231,-0.262059,-0.212339
46,-0.0688806,-0.00382343,-0.118271,-0.106065
57,-0.0611292,-0.0429703,0.157087,0.273022
30,-0.148326,0.000705215,-0.117912,-0.0738876
75,-0.0922151,0.0739731,0.381819,0.184797
36,-0.327373,-0.0714564,-0.0716715,0.0122736
83,-0.139851,-0.00497402,-0.00809047,0.157525
45,-0.195497,0.112687,0.267205,0.234066
96,0.208448,-0.00736661,0.183954,0.235123
80,0.265403,0.0625464,0.276629,0.211239
87,0.0247633,0.0349561,-0.0924504,0.096772
74,-0.0482161,-0.0272151,0.127538,0.0911537
79,0.129555,0.0714007,0.215282,0.157506
68,-0.0104722,0.0257527,0.040185,0.112285
47,-0.160444,0.0547308,-0.144683,-0.213655
39,0.213885,-0.0114348,0.292146,0.203336
24,-0.0828346,-0.10621,-0.0724009,-0.0125999
26,-0.160638,-0.0800465,-0.172458,-0.145502
90,0.0506792,0.0818943,0.286659,0.215379
72,-0.14386,-0.0846148,0.182198,0.0628666
29,0.0967242,-0.0468562,-0.0934876,-0.122433
52,0.0806517,-0.00881443,-0.242011,-0.1916
20,-0.0425303,0.10926,-0.0842061,-0.108818
77,0.244968,-0.0955562,0.237742,0.0779751
35,0.040195,0.115393,-0.241066,-0.279262
67,0.00453779,0.117976,0.193412,0.297003
44,-0.163425,0.0541219,-0.256398,-0.108577
32,-0.0858465,0.0512669,0.17525,0.11626
61,-0.0653615,0.132646,0.370469,0.151499
76,0.0386295,0.0125997,0.00828821,-0.00749389
92,-0.0240473,0.0780729,0.185499,0.118841
81,0.237409,0.0438824,0.348798,0.132085
64,-0.0892399,-0.0388476,0.260605,0.187089
66,0.136357,-0.0893717,0.316402,0.302292
94,-0.0674328,-0.019732,-0.105025,0.0545092
91,-0.0226551,-0.0199466,0.1021,0.0595146
65,-0.0515273,0.121866,-0.0427688,0.11651
60,-0.0459754,-0.107866,-0.202463,-0.246358
59,0.0581849,-0.0914111,0.283044,0.142344
78,-0.200102,0.0683032,0.330549,0.240857
19,0.0734702,-0.0623008,0.178387,0.156414
84,0.00700759,-0.04037,-0.0813166,0.0601303
18,-0.0238764,-0.0727087,-0.113774,-0.178858
89,0.0553141,0.0993202,0.171445,0.0793829
82,-0.0969213,0.0268565,-0.172867,-0.0800201
31,0.0153597,0.119339,-0.0438325,-0.207837
71,0.0260676,-0.0163364,-0.0470514,-0.15434
38,0.214941,0.08623,0.291322,0.317415
86,-0.0596544,-0.0549735,-0.33521,-0.192565
27,0.0188859,-0.0417688,-0.0440761,-0.0246491
55,0.0592398,0.106635,0.0449921,-0.0225237
42,0.0429515,-0.0215547,-0.0014751,0.0833099
33,-0.0631252,-0.0325847,0.0751417,-0.024855
93,-0.063859,-0.113796,0.110201,0.125286
58,0.106075,-0.0102766,0.0842237,0.106774
43,0.0535947,0.0343067,-0.18478,-0.0701008
16,-0.0117832,0.0581763,-0.119593,0.101735
