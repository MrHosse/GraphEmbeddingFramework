An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 78 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 36.76% 
Learning Progress: 36.76% 
9,0.171667,-0.143304,0.0374007,-0.102681
34,0.0961047,0.0119162,0.164546,-0.0705648
0,-2.18424,0.744968,2.05405,-1.94373
12,-0.42915,0.2294,0.327627,-0.123334
28,0.0442313,-0.0522002,-0.148657,0.123724
33,0.235314,-0.39753,-0.0877531,0.0653466
16,0.00606863,-0.00720738,0.00687398,-0.0737913
6,0.265784,0.0307784,-0.00607839,-0.0856306
17,-0.0107467,0.098162,0.0589301,-0.220827
27,0.0963886,-0.0702281,-0.0559221,-0.0134914
30,0.243532,-0.209972,-0.16674,0.0998791
2,0.229004,-0.158326,-0.136064,0.204656
18,-0.257365,0.206371,0.326971,-0.304076
1,0.338347,-0.123444,0.0439044,-0.0915646
3,0.348571,-0.153812,-0.237688,0.0968683
14,0.0997798,-0.162881,-0.152388,-0.110909
26,0.378264,-0.137587,-0.258453,0.25292
32,0.385657,-0.238164,-0.149001,-0.00583233
21,0.0541811,-0.177249,-0.138937,-0.00736562
29,0.200669,-0.157509,0.0975214,-0.0508733
11,-0.310445,0.0637963,0.230314,-0.0718393
31,0.0612561,-0.103297,-0.0510273,-0.0154962
20,-0.0912283,0.00732231,0.076844,-0.0707782
23,0.114611,-0.118754,0.0509963,0.108761
22,-0.235713,0.0418301,0.239573,-0.117896
13,-0.23514,0.0644953,0.25646,-0.270198
4,0.197694,-0.196177,-0.0702743,0.0824525
8,-0.324363,0.0671316,0.160726,-0.133063
7,0.191507,-0.163441,0.0652519,0.0705141
24,0.308827,-0.0699641,-0.152557,0.111058
19,0.0439262,-0.00783199,0.049629,-0.0770073
15,-0.00368782,-0.0496594,-0.0725981,0.113284
5,0.21258,-0.0690098,0.0386163,0.040416
25,0.201797,-0.24985,-0.179284,0.231541
10,0.0164677,0.0126149,-0.0299633,-0.188111
