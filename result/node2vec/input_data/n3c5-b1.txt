An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 90 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 27.78% 
Learning Progress: 0.00% 
Learning Progress: 55.56% 
Learning Progress: 83.33% 
32,0.373603,-0.221355,0.6534,-0.349226
6,0.898592,-0.674045,2.11931,-1.76361
4,0.964733,-0.667386,2.07048,-1.77161
10,0.388721,-0.219536,3.11646,-3.08919
8,0.0742659,-0.128885,3.64702,-2.90249
2,0.252133,-0.522231,3.42741,-2.73755
9,-0.197968,-0.423333,3.31318,-2.99916
1,-0.00101775,0.196617,2.95631,-3.31912
18,0.345034,-0.0940909,0.505933,-0.228149
31,0.538412,-0.205383,0.552445,-0.556779
5,0.710781,-0.563431,2.38866,-1.64625
24,0.40713,-0.335854,0.47603,-0.293165
42,0.420858,-0.340751,0.422849,-0.41812
35,0.350856,-0.284874,0.288236,-0.549268
16,0.356096,-0.00918556,0.423898,-0.272541
13,0.491955,-0.184887,0.659274,-0.415441
39,0.358709,-0.25868,0.532123,-0.506849
28,0.534896,-0.228486,0.666237,-0.34157
7,0.795583,-0.655908,2.14739,-1.6858
3,0.798383,-0.525936,2.11405,-1.67116
26,0.381395,-0.22931,0.737754,-0.20033
14,0.266102,-0.234431,0.568429,-0.324613
41,0.497931,-0.176115,0.535105,-0.446742
27,0.376543,-0.14145,0.626283,-0.296228
19,0.442473,-0.216281,0.697285,-0.445344
25,0.377872,-0.104399,0.558798,-0.505851
37,0.586588,-0.0897973,0.472335,-0.535427
11,0.210171,-0.192149,0.433159,-0.354553
34,0.439846,-0.258648,0.385696,-0.297688
43,0.355838,-0.0512128,0.418955,-0.552911
17,0.481243,-0.386123,0.345862,-0.552446
20,0.288744,-0.0140014,0.522786,-0.283807
38,0.413715,-0.193517,0.509546,-0.230897
30,0.397315,-0.128724,0.802398,-0.394124
45,0.455646,-0.147308,0.342324,-0.428737
44,0.358415,-0.0873358,0.408119,-0.300896
40,0.478381,-0.228101,0.757172,-0.551325
15,0.514712,-0.246457,0.609707,-0.40511
21,0.474167,-0.316434,0.576484,-0.394453
36,0.4092,-0.237607,0.473647,-0.402889
23,0.554665,0.041347,0.640971,-0.190425
12,0.321262,-0.174344,0.517474,-0.615317
29,0.402466,-0.0646346,0.665982,-0.324481
22,0.418834,-0.266154,0.479108,-0.380522
33,0.491445,-0.161349,0.533582,-0.397683
