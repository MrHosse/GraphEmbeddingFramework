An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 163 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 21.19% 
Learning Progress: 42.37% 
Learning Progress: 63.56% 
Learning Progress: 63.56% 
44,1.09736,-0.936872,-0.289646,1.51435
39,0.826821,-0.996713,-0.87853,0.811312
27,1.07442,-0.288211,-1.89785,0.524923
9,0.883725,-0.348127,-1.70007,0.552145
7,0.739146,-0.645707,-1.54663,0.388771
1,2.05496,2.83258,-5.31231,0.567466
37,1.08282,-2.11615,-0.259005,1.24935
36,1.24939,-2.38536,-0.349808,1.51807
24,1.05187,-2.39589,-0.359014,1.53066
22,0.906419,-2.31496,-0.216628,1.44795
19,0.970479,-2.47935,-0.296566,1.62327
18,0.953937,-2.59145,-0.266663,1.58542
17,0.74127,-2.37145,-0.339698,1.37284
16,0.584561,-2.07122,-0.501712,1.25359
15,0.634142,-1.77557,-0.676808,0.994664
11,0.549328,-1.52605,-0.720635,0.871329
10,0.525426,-1.03118,-0.990421,0.79338
29,1.41805,-2.39218,-0.309796,1.28928
26,1.09517,-2.2769,-0.131726,1.15883
20,1.13313,-2.05108,0.380412,0.619474
3,0.447794,-1.66216,-1.02162,0.23217
2,0.312142,-1.12454,-1.35906,-0.107213
46,0.78496,-0.992127,-0.142093,0.764381
45,1.22318,-1.12083,-0.363865,1.52114
48,1.33108,-1.53535,-0.194743,1.51496
47,1.48596,-1.58358,-0.373103,1.57834
43,3.93616,-0.967024,-1.82987,3.89552
31,0.803549,-0.872033,-1.16174,0.778781
51,0.927056,-1.74775,-0.174113,0.994728
38,1.02531,-1.92121,-0.157735,1.02721
25,0.944603,-2.09959,-0.206008,1.28812
40,1.08173,-1.28597,-0.869006,0.873563
6,1.46927,-2.00758,-0.00112076,0.597876
5,1.76513,-2.15497,0.154357,0.455571
4,3.87376,-4.89295,0.0797492,0.746373
57,0.713262,-1.37405,-0.1674,0.754727
49,1.26101,-1.75157,-0.316839,1.27334
12,1.49382,-2.09236,0.1884,0.501818
33,0.96739,-1.37268,-0.733921,0.792765
28,1.1777,-0.945779,-1.44733,0.613665
34,0.36304,-1.42435,-0.210683,0.742527
13,0.939014,-1.55317,0.26574,0.267507
23,0.716839,-2.06539,-0.205133,1.25905
21,0.662978,-2.08825,-0.226236,1.09151
50,1.23817,-1.96162,-0.452406,1.06672
52,0.930507,-1.83675,-0.214638,1.0822
53,1.14313,-1.94826,-0.310658,1.0987
41,1.21229,-1.96821,-0.177439,1.05191
32,1.26331,-1.86564,-0.00224048,0.878662
30,1.38224,-2.06124,0.023863,0.833328
14,1.16687,-1.72312,0.078261,0.537385
8,1.11507,-1.60845,0.146071,0.403663
58,0.664815,-1.18032,-0.0484168,0.819768
59,0.738753,-1.07659,-0.0372135,0.805961
35,0.315159,-1.26334,-0.12014,0.638199
54,0.640771,-1.40554,-0.0850053,0.839935
42,0.88297,-1.6584,-0.022533,0.80167
55,1.01144,-1.76488,-0.260741,0.999339
56,0.932756,-1.70535,-0.279224,0.857749
