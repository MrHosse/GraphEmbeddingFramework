An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 102 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 24.51% 
Learning Progress: 49.02% 
23,0.0992252,-0.052889,-0.111615,0.264891
33,0.0121799,0.0523043,0.114074,-0.157628
0,-7.32668,-2.45624,5.18255,-3.6678
14,0.0724593,0.106549,-0.00505358,0.433272
8,0.27698,0.0655946,-0.197741,0.20487
4,0.323899,0.0227384,-0.293954,0.523451
21,0.133069,0.0862908,-0.0617345,0.0646781
47,0.0436903,0.0736382,-0.087087,-0.0676333
29,-0.240286,0.0158498,-0.027559,-0.0389659
22,0.429378,0.0575287,0.947547,0.241082
36,0.00240526,-0.0882634,-0.0360882,-0.117718
19,0.287541,0.0161782,-0.0804013,0.211093
46,-0.1706,0.0745853,-0.049628,-0.0762389
32,-0.289387,-0.0997267,-0.0920232,-0.108666
17,-0.0732355,-0.0626701,-0.0493913,-0.0707517
40,-0.161418,-0.113908,-0.0381446,-0.143272
41,-0.156216,0.116815,0.13392,-0.148337
34,-0.125567,-0.115095,0.179421,-0.233123
44,-0.240362,-0.188734,0.0138845,0.008811
39,-0.20984,-0.149514,0.0941184,-0.00643199
11,0.0568243,-0.00595973,-0.129845,0.129023
37,0.169433,-0.115517,-0.0151663,0.155578
31,-0.173295,-0.0977713,0.176677,0.0591388
24,0.322593,0.0010142,-0.0654922,0.0324477
20,0.265777,-0.0279061,-0.683286,0.374561
48,-0.167743,-0.188846,0.130774,0.045391
43,0.0774083,-0.0501204,-0.0924415,0.18291
13,0.244334,0.00563439,-0.0399041,0.145181
7,0.420872,0.0294039,-0.0986559,0.325145
3,0.0774898,0.12768,-0.312461,0.472863
27,0.054885,-0.0626357,-0.228423,0.0467764
51,-0.200101,-0.0426147,0.0192716,-0.117669
30,-0.208676,-0.0816449,0.0327585,0.0140298
35,-0.174743,-0.12046,0.0220655,-0.0344801
2,-0.042641,0.0300368,-0.480783,0.376557
12,-0.197041,-0.087099,0.0595967,0.0981306
28,-0.100282,0.0765734,0.179071,-0.115346
1,0.262521,0.202208,0.0300749,0.257156
45,-0.0199138,-0.055812,-0.0186186,-0.133706
18,0.235194,-0.0365707,-0.256456,-0.259037
6,0.35311,0.0110466,-0.0744952,0.108917
42,-0.0803312,0.0179,-0.0283529,-0.117175
50,-0.139726,0.0729632,0.0354739,-0.40608
38,0.122284,0.0315789,0.155817,-0.301301
10,0.198792,0.0276464,-0.155368,-0.198644
15,0.00193932,0.0131013,0.342709,-0.0609727
5,-0.110052,-0.118423,0.163807,0.0632413
16,-0.0212053,-0.115179,-0.0360508,-0.223386
49,-0.248438,-0.0435641,0.11621,-0.105619
26,0.116762,-0.0861674,-0.128668,-0.0273839
9,0.0835205,0.102376,-0.183844,0.0146522
25,0.214587,-0.0756809,-0.286049,-0.352855
