An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 127 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 19.53% 
Learning Progress: 39.06% 
Learning Progress: 58.59% 
46,0.0117835,-0.51498,-0.17358,-0.0632551
5,0.0496555,-0.0962661,-0.222492,0.0981105
0,-5.16485,1.86173,8.62499,-2.45015
40,0.729719,0.259808,-0.605621,0.264638
19,0.597715,-0.0591675,-0.935454,0.256714
18,0.606305,-0.183833,-0.950657,0.307191
16,0.605477,-0.155751,-0.63618,-0.338113
6,0.49297,-0.369043,-0.477291,-0.00528918
4,0.347104,-0.408006,0.100835,-0.0428804
60,0.0637534,0.644043,-0.0906728,-0.171616
56,0.368139,0.142678,-0.0448958,0.108163
54,0.645897,-0.22703,0.0080757,0.514594
48,0.603631,0.0787389,-0.26312,0.190648
36,-0.00263346,-0.0936722,-0.114956,0.163429
11,-0.236883,-0.103717,-0.269811,-0.0382052
14,-0.459747,-0.064987,-0.281325,0.113297
10,0.605397,-0.264298,-0.260711,0.630319
9,0.117328,0.0664346,0.0204878,0.0980094
17,0.36719,-0.410617,-0.599731,0.628543
13,-0.415454,-0.0811434,-0.392613,0.00557517
12,0.0290578,0.0255236,-0.0899452,0.145297
22,0.237114,-0.0504837,0.00434662,0.451374
21,0.0831664,-0.235004,-0.441868,-0.071739
20,0.130523,-0.0843561,-0.0217591,-0.00812857
37,-0.0237374,-0.170705,-0.030558,-0.045052
23,-0.129164,-0.141682,-0.16714,0.0327744
45,0.040259,-0.126301,-0.020688,0.0663536
42,0.245415,-0.241483,-0.192282,0.41256
41,0.259598,0.257538,0.066951,0.126338
24,0.232947,-0.139698,-0.142884,0.161137
34,-0.0590125,-0.132487,0.0585122,-0.068367
33,0.256336,-0.410056,-0.142725,0.162814
8,0.784942,-0.313745,-0.28135,0.668978
7,0.726684,-0.384298,-0.175734,0.681145
2,0.111085,0.139665,-0.200943,0.112936
32,-0.0240277,0.0279865,-0.119607,0.0630565
1,0.301574,-0.0121247,-0.0441999,0.272188
3,0.650282,-0.122384,-0.397394,0.373978
26,7.22741e-05,0.435549,0.161175,0.0802081
31,0.0128469,0.0258311,-0.0478687,0.245038
30,0.0700624,0.136498,0.00287499,-0.0726939
29,0.137487,0.0948673,-0.164079,-0.0774807
55,0.7262,0.38518,-0.0576097,0.94039
51,0.455093,0.333795,-0.19462,0.390804
47,0.251797,-0.0820828,-0.31196,0.114183
27,0.144436,0.0989736,0.047891,0.0501556
62,0.179108,0.226795,-0.129363,-0.358314
61,0.0575644,0.149888,-0.1026,-0.221411
53,0.109009,-0.0672849,-0.450877,-0.19004
35,0.0178751,0.240362,0.0312921,0.354177
64,0.0413043,-0.0865579,0.000427739,0.0626252
63,0.144863,0.0362737,0.0248015,-0.315563
15,-0.290849,-0.253213,-0.184744,-0.103307
57,0.517197,0.11769,0.133306,0.976646
50,0.654686,-0.0487203,0.00104229,0.282609
52,0.210833,0.322561,-0.151359,0.081456
43,0.226136,0.547069,0.0108203,0.149241
49,0.379451,0.0905603,-0.344166,-0.149109
44,0.237641,-0.250783,0.0839146,0.0249004
39,0.527487,-0.195728,0.000450438,0.457703
25,0.0721962,0.152685,-0.0863787,-0.182264
58,0.4575,0.275393,0.593432,1.24291
38,0.292414,-0.234643,-0.112484,-0.0403313
59,-0.156648,0.599322,-0.453805,-0.181065
28,0.14769,-0.0543189,-0.0549538,-0.0195278
