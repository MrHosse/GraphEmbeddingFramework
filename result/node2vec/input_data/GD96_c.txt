An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 125 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 19.23% 
Learning Progress: 0.00% 
Learning Progress: 38.46% 
Learning Progress: 57.69% 
Learning Progress: 0.00% 
27,0.0559903,0.0910836,-0.000230525,-0.0537234
5,-0.0164985,-0.173811,0.0281814,0.0915269
0,-6.27433,-3.50987,6.52746,-9.54595
32,0.077558,0.193579,-0.0189358,0.0216713
28,0.398949,0.285942,-0.0971439,-0.0316524
12,0.34604,0.246006,-0.10063,0.0271117
4,0.500037,0.329349,-0.147618,0.0589712
35,0.244785,-0.021488,-0.0279426,0.10353
15,0.0436234,0.155069,0.0352404,-0.00907871
6,0.0523698,0.0952057,-0.0647227,-0.167685
29,0.0941673,-0.0621947,0.0319277,-0.118762
40,0.255226,0.0387819,-0.135457,0.182781
23,0.0904399,0.113767,-0.214861,-0.0291452
17,0.167752,0.0215496,-0.148826,-0.0381403
51,0.00565545,-0.0495537,-0.192419,-0.0438
20,-0.0586542,-0.0037807,-0.0364273,-0.126891
31,0.0536956,0.0975791,0.0507566,-0.046457
10,0.0746315,0.00823711,-0.0331626,-0.114544
2,0.0128571,0.129025,-0.00347323,-0.0990481
11,-0.0319674,-0.0395031,0.159859,-0.225275
52,-0.105047,-0.0759385,-0.18423,-0.0551703
14,-0.0554963,-0.0847247,0.299888,-0.291037
39,0.105698,-0.0706223,-0.139136,-0.18813
1,0.0328425,-0.0496802,-0.13886,-0.252203
41,0.11343,0.151679,-0.0695021,-0.127528
16,-0.00276123,-0.107119,-0.132827,0.000252766
8,0.069983,0.0333154,0.0661608,-0.235947
58,0.188132,0.0304339,-0.195508,0.0461643
49,0.0310045,0.10324,-0.0798051,-0.0573544
38,-0.0693437,-0.0857448,0.0234311,-0.0939546
46,0.0768977,-0.0394236,0.0261917,-0.0545742
19,-0.045529,0.075474,-0.0625927,-0.150967
9,0.125957,-0.0113482,0.126821,-0.0567712
63,-0.016783,-0.000166206,0.0855843,-0.22981
57,0.105694,0.252292,0.0922068,-0.427887
44,0.0614417,0.0598186,-0.0883286,-0.00918687
24,-0.140566,0.0136737,0.170244,-0.0683009
7,-0.234167,0.00557145,-0.0682223,-0.116216
22,-0.0447986,-0.0340007,0.101839,0.028598
47,-0.0319912,-0.0333202,-0.293212,0.0295671
45,0.10666,0.00904283,-0.104184,0.0466306
50,0.149631,0.0210895,-0.216533,-0.0290656
18,0.0649557,0.067629,-0.0303698,-0.0655668
34,-0.0551173,0.0187796,-0.0115239,0.179425
13,-0.00785289,0.113845,0.0097275,-0.0124247
65,-0.0853388,0.0261399,0.114896,-0.00943621
37,0.124482,0.124159,-0.0676795,0.0230932
3,-0.14441,-0.0578215,0.0784096,-0.0957767
42,-0.0307686,-0.0435181,-0.0869041,-0.0423863
59,0.0513294,-0.0403295,-0.0446266,-0.0692623
54,0.376052,0.122876,-0.213796,-0.101288
60,-0.0376321,0.00345117,-0.113114,-0.0504633
21,-0.0423347,-0.119623,-0.135973,0.0524868
56,0.039178,-0.0369097,-0.0613446,-0.123001
25,0.0712154,0.0213461,-0.0823153,-0.0552154
48,0.131811,0.111792,-0.151796,-0.0445889
26,-0.237304,-0.103371,-0.0421383,-0.0231835
64,-0.127887,-0.163881,-0.0565015,-0.198784
53,-0.0564618,0.136839,0.0149848,-0.0615973
33,0.0729986,0.0273608,-0.180143,-0.114112
55,-0.0860264,-0.0550418,-0.00777254,0.0548434
30,-0.056224,-0.0201773,-0.0117781,-0.10059
61,-0.108525,0.0349287,-0.283728,0.129136
43,0.135544,0.125705,-0.153006,-0.0191837
36,0.0941584,0.0873902,-0.0168476,0.00606685
62,0.287471,0.26803,-0.243275,0.0749073
