An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 72 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 35.71% 
Learning Progress: 35.71% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
17,0.0594248,-1.15842,0.693747,-1.01158
18,-0.436924,-2.01651,1.11802,-1.12499
2,-0.111071,-1.41397,0.961888,-0.936154
3,-0.466422,-2.07007,1.00184,-1.26575
16,-0.0559309,-1.81418,0.971549,-1.08534
4,-0.0449903,-1.01944,0.327468,-0.418173
0,0.512131,1.79774,-2.52742,3.01831
24,-0.443693,-1.72866,0.824648,-1.06187
27,-0.0430467,-0.254997,0.154122,-0.289306
34,0.0306404,0.131805,-0.281245,0.287423
23,0.10129,-0.556888,-0.0722757,-0.0993125
35,0.0984361,-0.448255,0.0614847,-0.104309
7,-0.143125,-0.49031,0.229514,-0.298218
29,-0.205692,-0.0857147,-0.0683972,0.198584
33,-0.107687,-0.100587,0.0181437,0.133426
26,0.283515,-0.488601,0.437346,-0.606744
13,-0.270029,-1.24415,0.959936,-1.05235
25,-0.271413,-2.15126,1.12957,-1.28956
31,-0.130365,-1.11604,0.863703,-0.89789
15,-0.106445,-0.052659,-0.104405,0.0726019
28,0.0212985,-0.0203258,-0.153088,0.101084
14,-0.145848,-0.242143,0.285875,-0.290799
8,-0.0248717,0.0927068,0.129873,-0.212534
30,-0.0874871,0.109089,0.0682734,-0.0551235
32,-0.0841354,0.294692,-0.121521,0.295056
19,0.0201673,0.0546007,-0.0244391,0.111563
20,0.0420114,0.275631,-0.286517,0.224919
11,-0.00370451,-0.364298,-0.0298572,0.060245
12,-0.0772347,0.00833579,0.0152709,-0.0115743
9,0.0157306,0.0880925,-0.0148198,0.147179
6,-0.323965,0.0358115,0.307324,-0.257166
22,-0.0620723,0.112639,-0.360085,0.35788
10,-0.114229,0.329028,-0.275573,0.339567
5,-0.121802,-0.0607207,0.0842982,-0.176901
21,-0.0456971,-0.100564,0.155126,-0.0229585
1,-0.014263,-0.345378,0.382879,-0.596003
