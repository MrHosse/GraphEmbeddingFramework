An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 16 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 62.50% 
Learning Progress: 0.00% 
Learning Progress: 62.50% 
Learning Progress: 0.00% 
9,-0.0723708,0.050186,0.0154107,0.0463371
0,-4.3504,3.67255,2.57343,-1.98455
16,-0.157041,-0.0227234,0.0732647,-0.165712
19,-0.00893962,0.00304878,-0.089061,0.0802673
3,-0.0294425,0.0938962,0.0543132,-0.0568981
12,-0.197926,0.0584992,0.102814,0.0260653
18,-0.0282753,-0.0082113,0.138275,-0.0643952
10,-0.0729418,0.0682423,0.123823,-0.100905
6,-0.0448845,0.053201,0.0706737,0.0631069
4,-0.0322126,0.214436,0.0433547,-0.14023
1,-0.10612,-0.0563699,0.153944,-0.174861
13,0.311207,-0.201456,-0.164123,0.215492
5,0.0141345,-0.0166995,-0.0682769,-0.0413261
17,-0.0388618,-0.142017,-0.0206907,0.00404424
15,0.206877,-0.196802,-0.263851,0.121022
11,0.158322,-0.281605,-0.225638,0.138928
14,0.118113,0.0997812,0.0182813,-0.0729113
7,0.0580215,-0.00528543,-0.0337951,-0.124734
2,-0.0432566,0.178805,-0.0358264,-0.0791373
8,0.0374432,-0.0907301,0.00598651,0.0768322
20,0.0879178,0.0440678,-0.121283,-0.119563
