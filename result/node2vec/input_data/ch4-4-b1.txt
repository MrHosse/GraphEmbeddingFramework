An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 144 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 17.36% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 34.72% 
Learning Progress: 52.08% 
Learning Progress: 69.44% 
Learning Progress: 86.81% 
Learning Progress: 69.44% 
64,-0.446734,0.25101,-0.0387669,0.403928
6,-0.477852,0.389805,0.54176,1.92253
10,-0.292826,0.461522,0.855113,2.46778
15,-0.568239,0.620575,2.23907,5.3535
3,-0.854584,0.18434,2.41277,5.27659
13,-0.452256,0.681326,2.17968,5.50297
16,-0.345731,0.764883,2.49008,4.93397
2,-0.776874,0.665259,2.36783,5.02929
14,-0.578994,0.80699,2.349,4.66418
4,-0.783225,0.838819,2.21561,4.72454
11,-0.72498,0.579215,2.05306,5.46217
60,-0.520563,0.208308,0.279241,0.489026
45,-0.275906,0.163902,0.0289493,0.532997
8,-0.637749,0.642108,1.05103,2.98917
59,-0.488737,0.285047,0.158342,0.419399
12,-0.458963,0.83045,2.61132,5.26951
69,-0.389949,0.401158,0.211413,0.21535
44,-0.414984,0.182427,0.146033,0.390379
22,-0.436789,0.228025,0.16193,0.328631
5,-0.509765,0.414965,0.549793,1.62782
23,-0.432327,0.135268,0.091582,0.337663
50,-0.507151,0.371359,0.23396,0.304849
7,-0.851435,0.454834,0.944677,2.78989
9,-0.824953,0.495151,0.983146,2.73407
62,-0.220161,0.138422,0.0790685,0.359834
30,-0.302732,0.243754,0.035216,0.467689
32,-0.19716,0.199575,0.162335,0.363843
26,-0.422426,0.218973,0.0767298,0.276044
52,-0.315438,0.25187,0.0380557,0.397535
66,-0.384268,0.115002,0.178129,0.400512
19,-0.323295,0.353,0.265847,0.50787
18,-0.365716,0.0619837,0.0305378,0.254144
41,-0.40918,0.456421,-0.112164,0.329449
46,-0.329809,0.245248,0.242681,0.557914
29,-0.369489,0.318081,0.0715409,0.378633
55,-0.357849,0.202141,0.302766,0.648588
48,-0.46488,0.213032,0.0317368,0.333117
17,-0.23317,0.0922752,0.253151,0.542378
40,-0.375645,0.135913,-0.0709105,0.335087
53,-0.532892,0.372212,0.210024,0.286877
37,-0.391782,0.236636,0.041067,0.36155
71,-0.298527,0.286015,0.116121,0.408693
36,-0.331155,0.263559,0.00365138,0.459181
54,-0.408807,0.169885,0.233342,0.519302
1,-0.533364,0.471975,0.684986,1.76637
42,-0.232662,0.100204,-0.0315725,0.381401
35,-0.302037,0.135789,0.124051,0.461649
56,-0.347837,0.246617,0.101602,0.561585
70,-0.399865,0.316944,0.269998,0.47949
67,-0.521038,0.372269,0.251758,0.366767
72,-0.244933,0.162356,0.0884878,0.518244
28,-0.438355,0.283539,0.0308912,0.323893
47,-0.206548,0.206535,0.164598,0.549955
58,-0.605359,0.355207,0.220923,0.411081
57,-0.478162,0.312868,0.131942,0.393199
38,-0.466179,0.281428,-0.107392,0.518967
63,-0.560493,0.200908,0.251722,0.36426
33,-0.308633,0.129864,0.20273,0.453481
21,-0.25526,0.265991,0.155057,0.514533
65,-0.299861,0.146413,0.239805,0.488286
24,-0.390565,0.156202,0.345929,0.433448
49,-0.347964,0.198643,-0.053279,0.292673
61,-0.323467,0.30452,0.232427,0.456825
68,-0.489415,0.215459,-0.0123053,0.424459
51,-0.388416,0.397757,-0.0803984,0.396899
39,-0.246604,0.272162,-0.105033,0.392235
25,-0.370869,0.223692,0.0535354,0.371487
31,-0.284364,0.125445,0.221249,0.409826
27,-0.403617,0.254927,0.0378437,0.470706
43,-0.228061,0.178569,0.0255928,0.544988
34,-0.162356,0.179878,0.0938623,0.480935
20,-0.283496,0.268883,0.523948,0.532527
