An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 50 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 32.89% 
3,-0.195374,-0.030299,0.177398,-0.00588439
14,-0.112917,-0.0113888,-0.342771,-0.0448069
0,3.5111,-0.677959,-2.35998,0.259307
5,-0.0901034,0.0867684,0.681786,-0.0923184
38,0.221067,-0.0240524,0.337909,0.00547915
18,0.143776,-0.0516036,-0.406709,0.0997802
30,0.288913,-0.170293,-0.478399,0.04706
11,-0.358895,-0.0128236,0.689821,-0.0897601
17,0.0725745,0.0414856,-0.163651,0.120165
31,0.263834,0.0177269,-0.401273,-0.0402896
13,0.0551127,-0.107265,-0.195322,-0.101956
25,0.297706,-0.177771,-0.433243,0.137997
10,-0.0512999,-0.00869251,0.908762,0.007169
7,0.191026,-0.103231,0.0804135,-0.133643
29,0.226488,-0.0318686,-0.359378,-0.0342575
35,0.0969199,0.0308787,0.00496269,0.0591052
36,0.24265,-0.0953098,-0.374004,-0.0876675
34,0.221329,-0.0891083,-0.270876,0.122572
32,0.241494,-0.103099,-0.240885,0.0964657
21,0.200475,-0.103597,-0.378829,0.0663022
15,-0.264779,-0.0179163,0.845714,0.0573632
1,-0.322931,0.033532,0.744829,0.00872834
4,0.352235,-0.0578982,-0.552218,-0.0539512
20,-0.00260949,0.0401655,0.0241809,0.121345
23,-0.270365,0.0132865,0.755912,-0.0827375
33,-0.0121483,0.0511986,0.0898714,-0.116567
2,-0.256734,0.109111,0.90501,-0.141501
6,-0.0725448,0.0376787,0.44925,0.0600275
28,0.0752725,-0.111546,-0.168621,0.0777745
12,0.257031,-0.0184299,-0.325531,-0.107886
9,0.352264,-0.127506,-0.339003,0.117031
19,0.0901049,0.0359405,-0.0754445,0.0221596
8,0.284548,-0.136259,-0.635327,0.104256
37,-0.155589,0.0277468,0.831369,-0.0363532
27,-0.340902,0.0941265,0.850164,-0.114535
22,-0.252044,0.0392558,0.495854,-0.049902
16,0.257497,-0.100748,-0.424318,-0.084174
24,0.139995,-0.0563189,0.0931274,0.0437506
26,0.254629,-0.161929,-0.249442,0.0906046
