An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 188 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 33.78% 
Learning Progress: 0.00% 
Learning Progress: 67.57% 
26,2.78497,2.91133,0.463902,-5.41164
32,2.6814,2.75902,0.522364,-5.40288
23,2.859,3.04016,0.553179,-5.64692
25,2.85553,2.90981,0.47834,-5.38366
21,3.37029,3.39522,0.459711,-6.07679
22,3.01294,3.09,0.413644,-5.68284
24,3.14523,3.18715,0.434323,-5.76867
31,2.72348,2.78103,0.657306,-5.38788
29,2.91298,2.81861,0.679885,-5.41138
3,2.93702,3.03184,0.801245,-5.78783
4,3.04343,2.94861,0.810375,-5.70346
30,2.74639,2.81587,0.709703,-5.47908
28,2.97938,2.80476,0.758921,-5.45319
18,3.64059,3.53241,0.497134,-6.5282
20,3.31327,3.2644,0.346461,-6.16994
16,3.78301,3.65563,0.528377,-6.87809
19,3.97261,3.92526,0.508843,-6.93751
17,3.86877,3.49423,0.571705,-6.71485
34,4.03969,3.86531,0.593035,-7.12683
35,4.1695,4.01483,0.666423,-7.32503
37,3.83622,3.74795,0.729433,-6.92555
15,3.84234,3.84567,0.578144,-7.01868
7,3.6514,3.6536,0.966396,-6.3913
2,3.20539,3.44294,0.944652,-5.9362
6,3.34682,3.41223,0.935691,-5.85769
8,3.37249,3.67027,0.97576,-6.26
5,3.34125,3.27341,0.852696,-5.92958
1,3.10815,2.94214,0.827245,-5.54222
14,3.5574,3.93075,0.839253,-6.55054
10,3.45063,4.02941,1.00922,-6.42927
9,3.6704,3.90594,1.01906,-6.61495
11,3.83711,4.1788,0.979824,-6.97771
12,3.84843,4.12261,0.813627,-7.10655
27,3.81085,4.33588,1.0234,-7.001
36,3.97797,3.69202,0.65289,-6.99038
33,2.77031,3.10975,0.682849,-5.11754
13,3.5553,3.9919,0.796895,-6.47693
