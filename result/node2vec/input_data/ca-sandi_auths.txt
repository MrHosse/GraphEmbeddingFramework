An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 123 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 14.53% 
Learning Progress: 29.07% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 43.60% 
Learning Progress: 58.14% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
46,0.00113551,-0.0817589,-0.056425,-0.0113488
11,0.113152,0.0141654,-0.0288422,0.304033
0,-1.0743,0.791745,5.23642,-4.12686
35,-0.100573,0.133402,0.228794,-0.0216806
7,-0.028295,0.0204932,-0.282208,0.101835
3,-0.0697525,-0.109801,-0.206589,-0.00432075
85,0.00656745,0.00845783,-0.244188,0.162268
36,0.422917,-0.172032,-0.800361,0.386586
26,0.0863042,0.0324268,-0.537372,0.306745
2,0.0833779,-0.0697232,-0.412081,0.059583
6,0.0929513,-0.115387,-0.0559339,0.0473128
56,-0.0242227,-0.00874724,-0.102791,0.145263
20,0.301027,-0.125814,-0.363583,0.309795
8,0.140403,-0.0662078,-0.175092,0.0717827
45,0.188509,-0.126715,-0.350788,0.245812
40,0.155059,-0.242413,-0.567997,0.28644
53,0.00205956,-0.00145249,-0.360181,0.465706
43,-0.125377,0.155113,-0.606291,0.394851
52,-0.0861478,-0.103662,-0.0604823,-0.127898
15,-0.0939501,0.0240963,-0.0446083,0.0938738
84,-0.0802368,-0.0137319,0.00118861,0.0369537
30,0.0672132,-0.0528049,-0.62535,0.294874
28,0.0342439,-0.0335319,0.016269,0.0629385
49,0.00157196,-0.033106,0.0562439,0.0672588
47,0.0887873,-0.134194,0.205217,-0.184033
75,0.0894544,-0.0542088,0.0718225,-0.146168
34,-0.150447,-0.0121001,-0.0867604,0.102706
33,0.175786,-0.174131,-0.62143,0.29014
24,0.137053,-0.175029,0.209729,-0.290996
22,0.0864944,-0.0222092,-0.20378,0.0346173
5,0.0778234,0.00969799,0.140017,-0.20195
13,-0.0739694,-0.0113946,0.173693,-0.172898
82,0.0352154,0.0218563,-0.176619,0.263255
67,-0.0646325,-0.129196,-0.0872512,0.102882
10,-0.0233525,0.0607947,-0.172557,-0.0172506
73,-0.189382,0.0449106,-0.156905,0.169867
44,0.0896995,-0.084137,-0.255592,0.205376
12,-0.0690299,0.0584328,0.0259106,-0.0536169
62,-0.0982985,0.047284,-0.191552,0.118267
16,-0.0911835,0.0114833,-0.266187,0.305059
80,0.103126,-0.0412455,0.0400297,-0.124355
54,0.0704265,-0.115434,-0.203793,0.119068
57,0.0224136,0.106708,-0.0651289,-0.192221
77,-0.0229303,-0.0801063,-0.0377784,-0.080743
55,-0.107054,0.206063,-0.267623,-0.0350303
27,0.174265,0.0140417,-0.00236969,-0.0839873
64,-0.043045,-0.0520847,-0.201123,0.269301
50,0.0346963,-0.188219,0.260688,-0.349105
32,0.20151,-0.0223272,-0.196032,0.0144302
18,0.152395,-0.167964,-0.203727,0.11417
83,-0.0205785,0.136104,-0.394885,0.179883
9,-0.109605,-0.112838,-0.314018,0.0195045
48,-0.0591837,-0.0154521,-0.161055,0.203158
41,-0.0121884,0.212558,-0.0810014,-0.0182352
37,-0.0104801,0.127202,0.114945,-0.151356
1,-0.0768114,0.0851466,0.140018,-0.221273
25,-0.0665304,0.0190481,-0.00289934,0.0198164
17,-0.0531727,-0.0652127,0.0972171,-0.0872962
86,0.00920439,-0.0282446,-0.0465997,0.0855142
38,-0.0066773,-0.0240475,0.125911,-0.281421
66,-0.040457,0.0596085,-0.0377834,0.160935
31,0.0440445,-0.0315041,-0.0440088,-0.0708562
23,-0.0360453,0.0983986,-0.564699,0.244664
51,-0.048969,-0.0652793,0.0111746,0.0536077
14,-0.0901991,-0.081986,0.0339003,-0.190223
39,0.0387288,-0.109563,-0.0694722,0.0653443
79,-0.233671,0.0526541,-0.234789,0.271622
78,-0.0566324,-0.0987219,-0.19624,0.162794
76,0.0744599,0.0435015,-0.230243,0.275208
72,0.0838132,0.0506826,-0.330217,0.307802
68,0.125453,0.0369639,-0.224383,0.105062
63,0.101483,0.0242866,0.262367,-0.323443
60,0.0759641,-0.0901474,0.0180105,-0.134146
29,-0.118759,0.134687,0.132785,-0.200791
58,-0.091445,0.126221,-0.224933,0.0159158
21,0.0593478,0.00971915,-0.0336464,-0.0142356
69,-0.073853,0.0147666,-0.304703,0.236067
81,-0.0185468,0.0642905,-0.0277925,0.0766677
70,-0.0476858,-0.0482459,0.213096,-0.128745
42,-0.0214661,0.018952,-0.281781,0.210535
59,0.0934675,-0.0206932,-0.247073,0.0221639
19,0.0165468,0.114279,0.227432,-0.29227
74,0.0276076,0.0660793,-0.0536649,0.144447
4,0.111122,-0.0769555,0.129004,0.0578239
61,-0.0224326,-0.0659418,-0.160889,0.052563
65,0.0578649,-0.0695818,-0.0843117,-0.0493045
71,0.0388096,-0.00963074,-0.0137827,-0.0281561
