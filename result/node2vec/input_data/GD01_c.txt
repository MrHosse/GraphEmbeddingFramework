An algorithmic framework for representational learning on graphs. [Jul  3 2023]
================================================================================
Input graph path (-i:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph
Output graph path (-o:)=/home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.emb
Number of dimensions. Default is 128 (-d:)=4
Length of walk per source. Default is 80 (-l:)=80
Number of walks per source. Default is 10 (-r:)=10
Context size for optimization. Default is 10 (-k:)=10
Number of epochs in SGD. Default is 1 (-e:)=1
Return hyperparameter. Default is 1 (-p:)=1
Inout hyperparameter. Default is 1 (-q:)=1
Verbose output. (-v)=YES
Graph is directed. (-dr)=YES
Graph is weighted. (-w)=YES
Output random walks instead of embeddings. (-ow)=NO
Read 135 lines from /home/hgholizadeh/GEF/embedding/node2vec_exe/temp_graph.graph

Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 
Preprocessing progress: 0.00% 

Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%
Walking Progress: 0.00%

Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 0.00% 
Learning Progress: 37.88% 
Learning Progress: 0.00% 
32,-0.466649,1.29805,0.119591,0.353241
33,0.0648778,1.34236,-0.690262,0.0263635
0,-0.688102,-1.30391,1.86527,3.90409
17,0.196599,1.41898,-0.460046,-0.726679
21,0.38056,1.12627,-0.351097,-0.888428
27,0.335723,1.42602,-0.322859,-0.636195
28,0.260022,1.38575,-0.486156,-0.654515
29,0.395849,1.48273,-0.24148,-0.814579
30,0.463433,1.24547,-0.303049,-0.517407
31,0.206816,1.20824,-0.413104,-0.640893
10,0.185827,0.804836,-0.34929,-0.747935
11,0.629737,1.70956,-0.339185,-1.13194
18,-0.0948328,0.18328,0.00425628,-0.00752825
9,0.575658,0.637691,-0.260718,-0.890877
16,0.100553,0.79672,-0.406484,-0.731038
23,0.462078,1.68146,-0.417689,-0.986907
26,0.293742,1.37454,-0.467793,-1.06376
25,0.371037,1.62913,-0.464063,-0.873911
12,0.568153,1.37071,-0.463386,-0.929716
8,0.34243,0.894051,-0.626369,-0.665904
19,-0.161912,0.0796485,0.0618056,0.102865
13,0.659812,0.860082,-0.232542,-0.834937
22,0.560059,1.58365,-0.404573,-1.0716
15,0.40611,1.17728,-0.31331,-0.974517
20,0.421658,1.25261,-0.259808,-1.09221
7,0.615042,1.1777,-0.307582,-1.13479
14,0.688313,1.15796,-0.283661,-0.998763
1,0.625601,0.781244,-0.308674,-0.910364
2,0.696864,0.893451,-0.2668,-1.16688
3,0.699811,1.17194,-0.394182,-1.1989
24,0.566382,1.13273,-0.388111,-0.644313
6,0.329551,0.597863,-0.37585,-0.587113
4,0.598593,0.782134,-0.642457,-0.640644
5,0.601118,0.964439,-0.45002,-0.663919
